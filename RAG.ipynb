{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":108523,"status":"ok","timestamp":1739323446578,"user":{"displayName":"Wai Leuk Lo","userId":"04142260838791272738"},"user_tz":-480},"id":"RrnLpVZiw-lR","outputId":"1efc1699-9274-45ce-8de3-b39f8ce25d1a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.17)\n","Collecting langchain_community\n","  Downloading langchain_community-0.3.17-py3-none-any.whl.metadata (2.4 kB)\n","Collecting langchain_huggingface\n","  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n","Collecting langchain_openai\n","  Downloading langchain_openai-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n","Collecting langgraph\n","  Downloading langgraph-0.2.71-py3-none-any.whl.metadata (17 kB)\n","Collecting langchain_chroma\n","  Downloading langchain_chroma-0.2.1-py3-none-any.whl.metadata (1.7 kB)\n","Collecting langchain_anthropic\n","  Downloading langchain_anthropic-0.3.7-py3-none-any.whl.metadata (1.9 kB)\n","Collecting langgraph-checkpoint-sqlite\n","  Downloading langgraph_checkpoint_sqlite-2.0.3-py3-none-any.whl.metadata (3.0 kB)\n","Collecting pypdf\n","  Downloading pypdf-5.3.0-py3-none-any.whl.metadata (7.2 kB)\n","Collecting datasets\n","  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n","Collecting ragas\n","  Downloading ragas-0.2.13-py3-none-any.whl.metadata (8.3 kB)\n","Collecting ragatouille\n","  Downloading RAGatouille-0.0.9-py3-none-any.whl.metadata (28 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.33)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n","Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n","Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n","Collecting langchain-core<0.4.0,>=0.3.33 (from langchain)\n","  Downloading langchain_core-0.3.34-py3-none-any.whl.metadata (5.9 kB)\n","Collecting langchain\n","  Downloading langchain-0.3.18-py3-none-any.whl.metadata (7.8 kB)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n","  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n","Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n","  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n","Collecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain)\n","  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (0.28.1)\n","Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (3.4.1)\n","Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (0.21.0)\n","Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (4.48.2)\n","Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.61.1)\n","Collecting tiktoken<1,>=0.7 (from langchain_openai)\n","  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n","  Downloading langgraph_checkpoint-2.0.12-py3-none-any.whl.metadata (4.6 kB)\n","Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n","  Downloading langgraph_sdk-0.1.51-py3-none-any.whl.metadata (1.8 kB)\n","Collecting chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0 (from langchain_chroma)\n","  Downloading chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n","Collecting fastapi<1,>=0.95.2 (from langchain_chroma)\n","  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n","Collecting anthropic<1,>=0.45.0 (from langchain_anthropic)\n","  Downloading anthropic-0.45.2-py3-none-any.whl.metadata (23 kB)\n","Collecting aiosqlite<0.21.0,>=0.20.0 (from langgraph-checkpoint-sqlite)\n","  Downloading aiosqlite-0.20.0-py3-none-any.whl.metadata (4.3 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ragas) (1.6.0)\n","Collecting appdirs (from ragas)\n","  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n","Collecting diskcache>=5.6.3 (from ragas)\n","  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n","Collecting llama-index (from ragatouille)\n","  Downloading llama_index-0.12.16-py3-none-any.whl.metadata (12 kB)\n","Collecting faiss-cpu (from ragatouille)\n","  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n","Collecting colbert-ai>=0.2.19 (from ragatouille)\n","  Downloading colbert_ai-0.2.21-py3-none-any.whl.metadata (12 kB)\n","Collecting onnx (from ragatouille)\n","  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n","Requirement already satisfied: srsly in /usr/local/lib/python3.11/dist-packages (from ragatouille) (2.5.1)\n","Collecting voyager (from ragatouille)\n","  Downloading voyager-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n","Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.11/dist-packages (from ragatouille) (2.5.1+cu124)\n","Collecting fast-pytorch-kmeans (from ragatouille)\n","  Downloading fast_pytorch_kmeans-0.2.2-py3-none-any.whl.metadata (1.1 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n","Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.11/dist-packages (from aiosqlite<0.21.0,>=0.20.0->langgraph-checkpoint-sqlite) (4.12.2)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.45.0->langchain_anthropic) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.45.0->langchain_anthropic) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.45.0->langchain_anthropic) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.45.0->langchain_anthropic) (0.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.45.0->langchain_anthropic) (1.3.1)\n","Collecting build>=1.0.3 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n","Collecting chroma-hnswlib==0.7.6 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n","Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n","Collecting posthog>=2.4.0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading posthog-3.12.1-py2.py3-none-any.whl.metadata (2.9 kB)\n","Collecting onnxruntime>=1.14.1 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n","Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.16.0)\n","Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n","Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl.metadata (2.2 kB)\n","Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.16.0)\n","Collecting pypika>=0.48.9 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading PyPika-0.48.9.tar.gz (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting overrides>=7.3.1 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (6.5.2)\n","Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.70.0)\n","Collecting bcrypt>=4.0.1 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n","Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.15.1)\n","Collecting kubernetes>=28.1.0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading kubernetes-32.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n","Collecting mmh3>=4.0.1 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n","Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (3.10.15)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (13.9.4)\n","Collecting bitarray (from colbert-ai>=0.2.19->ragatouille)\n","  Downloading bitarray-3.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\n","Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (from colbert-ai>=0.2.19->ragatouille) (3.1.0)\n","Collecting git-python (from colbert-ai>=0.2.19->ragatouille)\n","  Downloading git_python-1.0.3-py2.py3-none-any.whl.metadata (331 bytes)\n","Collecting python-dotenv (from colbert-ai>=0.2.19->ragatouille)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Collecting ninja (from colbert-ai>=0.2.19->ragatouille)\n","  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from colbert-ai>=0.2.19->ragatouille) (1.13.1)\n","Collecting ujson (from colbert-ai>=0.2.19->ragatouille)\n","  Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n","Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Collecting starlette<0.46.0,>=0.40.0 (from fastapi<1,>=0.95.2->langchain_chroma)\n","  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (1.33)\n","Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.6.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (11.1.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->ragatouille) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->ragatouille) (3.1.5)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13->ragatouille)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13->ragatouille)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13->ragatouille)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13->ragatouille)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13->ragatouille)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13->ragatouille)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13->ragatouille)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13->ragatouille)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13->ragatouille)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->ragatouille) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->ragatouille) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13->ragatouille)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->ragatouille) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->ragatouille) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13->ragatouille) (1.3.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain_huggingface) (0.5.2)\n","Collecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama-index->ragatouille)\n","  Downloading llama_index_agent_openai-0.4.5-py3-none-any.whl.metadata (727 bytes)\n","Collecting llama-index-cli<0.5.0,>=0.4.0 (from llama-index->ragatouille)\n","  Downloading llama_index_cli-0.4.0-py3-none-any.whl.metadata (1.5 kB)\n","Collecting llama-index-core<0.13.0,>=0.12.16 (from llama-index->ragatouille)\n","  Downloading llama_index_core-0.12.17-py3-none-any.whl.metadata (2.5 kB)\n","Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama-index->ragatouille)\n","  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n","Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index->ragatouille)\n","  Downloading llama_index_indices_managed_llama_cloud-0.6.4-py3-none-any.whl.metadata (3.6 kB)\n","Collecting llama-index-llms-openai<0.4.0,>=0.3.0 (from llama-index->ragatouille)\n","  Downloading llama_index_llms_openai-0.3.18-py3-none-any.whl.metadata (3.3 kB)\n","Collecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 (from llama-index->ragatouille)\n","  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n","Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama-index->ragatouille)\n","  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n","Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama-index->ragatouille)\n","  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n","Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama-index->ragatouille)\n","  Downloading llama_index_readers_file-0.4.5-py3-none-any.whl.metadata (5.4 kB)\n","Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index->ragatouille)\n","  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n","Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index->ragatouille) (3.9.1)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx->ragatouille) (4.25.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from srsly->ragatouille) (2.0.10)\n","Collecting pyproject_hooks (from build>=1.0.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic<1,>=0.45.0->langchain_anthropic) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic<1,>=0.45.0->langchain_anthropic) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain) (3.0.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.17.0)\n","Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (2.27.0)\n","Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.8.0)\n","Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (2.0.0)\n","Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (3.2.2)\n","Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n","Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index->ragatouille) (1.2.18)\n","Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.16->llama-index->ragatouille)\n","  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n","Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.16->llama-index->ragatouille)\n","  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index->ragatouille) (1.17.2)\n","Collecting llama-cloud<0.2.0,>=0.1.8 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->ragatouille)\n","  Downloading llama_cloud-0.1.12-py3-none-any.whl.metadata (851 bytes)\n","Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->ragatouille) (4.13.3)\n","Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->ragatouille)\n","  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n","Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n","  Downloading llama_parse-0.6.1-py3-none-any.whl.metadata (6.9 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index->ragatouille) (8.1.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index->ragatouille) (1.4.2)\n","Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (25.1.24)\n","Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (75.1.0)\n","Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.66.0)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl.metadata (1.9 kB)\n","Collecting opentelemetry-proto==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_proto-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n","Collecting opentelemetry-sdk>=1.2.0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n","Collecting protobuf>=3.20.2 (from onnx->ragatouille)\n","  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n","Collecting opentelemetry-instrumentation-asgi==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl.metadata (2.1 kB)\n","Collecting opentelemetry-instrumentation==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl.metadata (6.3 kB)\n","Collecting opentelemetry-semantic-conventions==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl.metadata (2.5 kB)\n","Collecting opentelemetry-util-http==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl.metadata (2.6 kB)\n","Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n","Collecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n","Collecting importlib-metadata<=8.5.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n","Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n","Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (2.18.0)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.5.4)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n","Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (14.2)\n","Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask->colbert-ai>=0.2.19->ragatouille) (3.1.3)\n","Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask->colbert-ai>=0.2.19->ragatouille) (2.2.0)\n","Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask->colbert-ai>=0.2.19->ragatouille) (1.9.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13->ragatouille) (3.0.2)\n","Requirement already satisfied: gitpython in /usr/local/lib/python3.11/dist-packages (from git-python->colbert-ai>=0.2.19->ragatouille) (3.1.44)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->ragatouille) (2.6)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (5.5.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (4.9)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (3.21.0)\n","Collecting llama-cloud-services>=0.6.1 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n","  Downloading llama_cloud_services-0.6.1-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.1.2)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython->git-python->colbert-ai>=0.2.19->ragatouille) (4.0.12)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython->git-python->colbert-ai>=0.2.19->ragatouille) (5.0.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.6.1)\n","Downloading langchain_community-0.3.17-py3-none-any.whl (2.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain-0.3.18-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n","Downloading langchain_openai-0.3.5-py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.0/55.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langgraph-0.2.71-py3-none-any.whl (149 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.0/150.0 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_chroma-0.2.1-py3-none-any.whl (11 kB)\n","Downloading langchain_anthropic-0.3.7-py3-none-any.whl (22 kB)\n","Downloading langgraph_checkpoint_sqlite-2.0.3-py3-none-any.whl (12 kB)\n","Downloading pypdf-5.3.0-py3-none-any.whl (300 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.7/300.7 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ragas-0.2.13-py3-none-any.whl (178 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.3/178.3 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading RAGatouille-0.0.9-py3-none-any.whl (45 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiosqlite-0.20.0-py3-none-any.whl (15 kB)\n","Downloading anthropic-0.45.2-py3-none-any.whl (222 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.8/222.8 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colbert_ai-0.2.21-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.1/116.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n","Downloading langchain_core-0.3.34-py3-none-any.whl (412 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.0/413.0 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n","Downloading langgraph_checkpoint-2.0.12-py3-none-any.whl (38 kB)\n","Downloading langgraph_sdk-0.1.51-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n","Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m114.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n","Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fast_pytorch_kmeans-0.2.2-py3-none-any.whl (9.8 kB)\n","Downloading llama_index-0.12.16-py3-none-any.whl (6.9 kB)\n","Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading voyager-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n","Downloading kubernetes-32.0.0-py2.py3-none-any.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llama_index_agent_openai-0.4.5-py3-none-any.whl (13 kB)\n","Downloading llama_index_cli-0.4.0-py3-none-any.whl (27 kB)\n","Downloading llama_index_core-0.12.17-py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n","Downloading llama_index_indices_managed_llama_cloud-0.6.4-py3-none-any.whl (13 kB)\n","Downloading llama_index_llms_openai-0.3.18-py3-none-any.whl (14 kB)\n","Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n","Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n","Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n","Downloading llama_index_readers_file-0.4.5-py3-none-any.whl (39 kB)\n","Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n","Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m118.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl (18 kB)\n","Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl (18 kB)\n","Downloading opentelemetry_proto-1.30.0-py3-none-any.whl (55 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl (12 kB)\n","Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl (30 kB)\n","Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl (16 kB)\n","Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl (177 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_util_http-0.51b0-py3-none-any.whl (7.3 kB)\n","Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl (118 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n","Downloading posthog-3.12.1-py2.py3-none-any.whl (72 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bitarray-3.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (286 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading git_python-1.0.3-py2.py3-none-any.whl (1.9 kB)\n","Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n","Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n","Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n","Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n","Downloading llama_cloud-0.1.12-py3-none-any.whl (252 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llama_parse-0.6.1-py3-none-any.whl (4.8 kB)\n","Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n","Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n","Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m108.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n","Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n","Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llama_cloud_services-0.6.1-py3-none-any.whl (22 kB)\n","Building wheels for collected packages: pypika\n","  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53771 sha256=8902185cb0b2a8d610aa756a7e849bdd74473eef265e122b0ef46121f9d66cf3\n","  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n","Successfully built pypika\n","Installing collected packages: striprtf, pypika, monotonic, filetype, durationpy, dirtyjson, bitarray, appdirs, xxhash, voyager, uvloop, uvicorn, ujson, python-dotenv, pyproject_hooks, pypdf, protobuf, overrides, opentelemetry-util-http, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, mypy-extensions, mmh3, marshmallow, importlib-metadata, humanfriendly, httpx-sse, httptools, fsspec, faiss-cpu, diskcache, dill, chroma-hnswlib, bcrypt, backoff, asgiref, aiosqlite, watchfiles, typing-inspect, tiktoken, starlette, posthog, opentelemetry-proto, opentelemetry-api, onnx, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, coloredlogs, build, pydantic-settings, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, onnxruntime, nvidia-cusolver-cu12, llama-cloud, langgraph-sdk, kubernetes, git-python, fastapi, dataclasses-json, anthropic, opentelemetry-sdk, opentelemetry-instrumentation, llama-index-core, langchain-core, datasets, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, langgraph-checkpoint, langchain-text-splitters, langchain_openai, langchain_anthropic, fast-pytorch-kmeans, colbert-ai, opentelemetry-instrumentation-fastapi, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, langgraph-checkpoint-sqlite, langgraph, langchain_huggingface, langchain, llama-index-readers-llama-parse, llama-index-program-openai, langchain_community, chromadb, ragas, llama-index-question-gen-openai, langchain_chroma, llama-index, ragatouille\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 4.25.6\n","    Uninstalling protobuf-4.25.6:\n","      Successfully uninstalled protobuf-4.25.6\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib_metadata 8.6.1\n","    Uninstalling importlib_metadata-8.6.1:\n","      Successfully uninstalled importlib_metadata-8.6.1\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","  Attempting uninstall: opentelemetry-api\n","    Found existing installation: opentelemetry-api 1.16.0\n","    Uninstalling opentelemetry-api-1.16.0:\n","      Successfully uninstalled opentelemetry-api-1.16.0\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: opentelemetry-semantic-conventions\n","    Found existing installation: opentelemetry-semantic-conventions 0.37b0\n","    Uninstalling opentelemetry-semantic-conventions-0.37b0:\n","      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","  Attempting uninstall: opentelemetry-sdk\n","    Found existing installation: opentelemetry-sdk 1.16.0\n","    Uninstalling opentelemetry-sdk-1.16.0:\n","      Successfully uninstalled opentelemetry-sdk-1.16.0\n","  Attempting uninstall: langchain-core\n","    Found existing installation: langchain-core 0.3.33\n","    Uninstalling langchain-core-0.3.33:\n","      Successfully uninstalled langchain-core-0.3.33\n","  Attempting uninstall: langchain-text-splitters\n","    Found existing installation: langchain-text-splitters 0.3.5\n","    Uninstalling langchain-text-splitters-0.3.5:\n","      Successfully uninstalled langchain-text-splitters-0.3.5\n","  Attempting uninstall: langchain\n","    Found existing installation: langchain 0.3.17\n","    Uninstalling langchain-0.3.17:\n","      Successfully uninstalled langchain-0.3.17\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed aiosqlite-0.20.0 anthropic-0.45.2 appdirs-1.4.4 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 bitarray-3.0.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.6.3 colbert-ai-0.2.21 coloredlogs-15.0.1 dataclasses-json-0.6.7 datasets-3.2.0 dill-0.3.8 dirtyjson-1.0.8 diskcache-5.6.3 durationpy-0.9 faiss-cpu-1.10.0 fast-pytorch-kmeans-0.2.2 fastapi-0.115.8 filetype-1.2.0 fsspec-2024.9.0 git-python-1.0.3 httptools-0.6.4 httpx-sse-0.4.0 humanfriendly-10.0 importlib-metadata-8.5.0 kubernetes-32.0.0 langchain-0.3.18 langchain-core-0.3.34 langchain-text-splitters-0.3.6 langchain_anthropic-0.3.7 langchain_chroma-0.2.1 langchain_community-0.3.17 langchain_huggingface-0.1.2 langchain_openai-0.3.5 langgraph-0.2.71 langgraph-checkpoint-2.0.12 langgraph-checkpoint-sqlite-2.0.3 langgraph-sdk-0.1.51 llama-cloud-0.1.12 llama-cloud-services-0.6.1 llama-index-0.12.16 llama-index-agent-openai-0.4.5 llama-index-cli-0.4.0 llama-index-core-0.12.17 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.4 llama-index-llms-openai-0.3.18 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.5 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.1 marshmallow-3.26.1 mmh3-5.1.0 monotonic-1.6 multiprocess-0.70.16 mypy-extensions-1.0.0 ninja-1.11.1.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnx-1.17.0 onnxruntime-1.20.1 opentelemetry-api-1.30.0 opentelemetry-exporter-otlp-proto-common-1.30.0 opentelemetry-exporter-otlp-proto-grpc-1.30.0 opentelemetry-instrumentation-0.51b0 opentelemetry-instrumentation-asgi-0.51b0 opentelemetry-instrumentation-fastapi-0.51b0 opentelemetry-proto-1.30.0 opentelemetry-sdk-1.30.0 opentelemetry-semantic-conventions-0.51b0 opentelemetry-util-http-0.51b0 overrides-7.7.0 posthog-3.12.1 protobuf-5.29.3 pydantic-settings-2.7.1 pypdf-5.3.0 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.0.1 ragas-0.2.13 ragatouille-0.0.9 starlette-0.45.3 striprtf-0.0.26 tiktoken-0.8.0 typing-inspect-0.9.0 ujson-5.10.0 uvicorn-0.34.0 uvloop-0.21.0 voyager-2.1.0 watchfiles-1.0.4 xxhash-3.5.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["importlib_metadata"]},"id":"48bcb54e916e41769d9f6f066db88446"}},"metadata":{}}],"source":["!pip install langchain langchain_community langchain_huggingface langchain_openai langgraph langchain_chroma langchain_anthropic langgraph-checkpoint-sqlite pypdf datasets ragas ragatouille"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xmXZVpMQwrsX","executionInfo":{"status":"ok","timestamp":1739323490916,"user_tz":-480,"elapsed":44326,"user":{"displayName":"Wai Leuk Lo","userId":"04142260838791272738"}},"outputId":"990ef26a-d3b1-42f2-9efa-70fb5b9f6c16"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1860,"status":"ok","timestamp":1739323492789,"user":{"displayName":"Wai Leuk Lo","userId":"04142260838791272738"},"user_tz":-480},"id":"VPENRVT3sngt","outputId":"1bc50c26-cf17-411f-b599-193deffcc46c"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Documents/General reference/J/Job/Master Concept\n"]}],"source":["%cd \"/content/drive/MyDrive/Documents/General reference/J/Job/Master Concept/\""]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1378,"status":"ok","timestamp":1739323494166,"user":{"displayName":"Wai Leuk Lo","userId":"04142260838791272738"},"user_tz":-480},"id":"8z6AMf2FzVv5","outputId":"9257ee1a-4900-4555-ae2e-813c447979b3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":7}],"source":["from dotenv import load_dotenv\n","\n","load_dotenv()  # take environment variables from .env."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5147,"status":"ok","timestamp":1739323499319,"user":{"displayName":"Wai Leuk Lo","userId":"04142260838791272738"},"user_tz":-480},"id":"xaWqEjoAxKjS","outputId":"9467a980-0e0f-49fb-d859-b44fcdf0fd6a"},"outputs":[{"output_type":"stream","name":"stdout","text":["38\n"]}],"source":["from langchain_community.document_loaders import PyPDFLoader\n","\n","file_path = \"./2022hkt_security_report.pdf\"\n","loader = PyPDFLoader(file_path)\n","\n","docs = loader.load()\n","\n","print(len(docs))"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1739323499339,"user":{"displayName":"Wai Leuk Lo","userId":"04142260838791272738"},"user_tz":-480},"id":"93kiOHKvxybv","outputId":"46f194d2-5780-422c-c086-a6e8127a2ae4"},"outputs":[{"output_type":"stream","name":"stdout","text":["HKT Hong Kong Enterprise \n","Cyber Security Readiness \n","Index 2022 \n"," \n","April 2018\n","{'producer': '適用於 Microsoft 365 的 Microsoft® Word', 'creator': '適用於 Microsoft 365 的 Microsoft® Word', 'creationdate': '2022-11-18T12:34:46+08:00', 'author': 'HKCERT', 'moddate': '2022-11-18T12:45:00+08:00', 'title': 'HKT Hong Kong Enterprise Cyber Security Readiness Index 2022', 'source': './2022hkt_security_report.pdf', 'total_pages': 38, 'page': 0, 'page_label': '1'}\n"]}],"source":["print(docs[0].page_content[0:100])\n","print(docs[0].metadata)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":1194,"status":"ok","timestamp":1739323500535,"user":{"displayName":"Wai Leuk Lo","userId":"04142260838791272738"},"user_tz":-480},"id":"6zFcBxYtyEdx"},"outputs":[],"source":["from langchain_openai import ChatOpenAI\n","\n","llm = ChatOpenAI(model=\"gpt-4o\")"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":6387,"status":"ok","timestamp":1739323506932,"user":{"displayName":"Wai Leuk Lo","userId":"04142260838791272738"},"user_tz":-480},"id":"XyF9Gga_zscm"},"outputs":[],"source":["from langchain_core.vectorstores import InMemoryVectorStore\n","from langchain_openai import OpenAIEmbeddings\n","from langchain_text_splitters import RecursiveCharacterTextSplitter\n","\n","text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=700)\n","splits = text_splitter.split_documents(docs)\n","vectorstore = InMemoryVectorStore.from_documents(\n","    documents=splits, embedding=OpenAIEmbeddings()\n",")\n","\n","retriever = vectorstore.as_retriever()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1739323506945,"user":{"displayName":"Wai Leuk Lo","userId":"04142260838791272738"},"user_tz":-480},"id":"Rp22TqiqjTum","outputId":"227d7135-604c-43d2-8ee4-89a84b73d923"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["145"]},"metadata":{},"execution_count":12}],"source":["len(splits)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2464,"status":"ok","timestamp":1739323509410,"user":{"displayName":"Wai Leuk Lo","userId":"04142260838791272738"},"user_tz":-480},"id":"fdaskeCTz67K","outputId":"6a5653c2-e244-4bc9-ba82-53a058a71eda"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input': \"What's the content of the document?\",\n"," 'context': [Document(id='36ed43c9-03a2-4e01-97a8-a5261bab41d7', metadata={'producer': '適用於 Microsoft 365 的 Microsoft® Word', 'creator': '適用於 Microsoft 365 的 Microsoft® Word', 'creationdate': '2022-11-18T12:34:46+08:00', 'author': 'HKCERT', 'moddate': '2022-11-18T12:45:00+08:00', 'title': 'HKT Hong Kong Enterprise Cyber Security Readiness Index 2022', 'source': './2022hkt_security_report.pdf', 'total_pages': 38, 'page': 1, 'page_label': '2'}, page_content='0 | P a g e \\nTable of Content \\n \\n1. Introduction ................................................................................................ 1 \\n1.1 Background ....................................................................................................................... 1 \\n1.2 HKT Hong Kong Enterprise Cyber Security Readiness Index Survey ................................ 1 \\n1.3 Thematic Survey of the Year ............................................................................................ 2 \\n1.4 Structure of Report ........................................................................................................... 2 \\n2. Methodology .............................................................................................. 3 \\n2.1 Framework of the Index ................................................................................................... 3'),\n","  Document(id='c9af8c19-43c4-47f2-be90-58b8ad511f5c', metadata={'producer': '適用於 Microsoft 365 的 Microsoft® Word', 'creator': '適用於 Microsoft 365 的 Microsoft® Word', 'creationdate': '2022-11-18T12:34:46+08:00', 'author': 'HKCERT', 'moddate': '2022-11-18T12:45:00+08:00', 'title': 'HKT Hong Kong Enterprise Cyber Security Readiness Index 2022', 'source': './2022hkt_security_report.pdf', 'total_pages': 38, 'page': 37, 'page_label': '38'}, page_content='36 | P a g e \\nDisclaimer \\nHKPC and HKCERT shall not have any liability, duty or obligation for or relating to the content and data contained herein, any \\nerrors, inaccuracies, omissions or delays in the content and data, or for any actions taken in reliance thereon. In no event \\nshall HKPC be liable for any special, incidental or consequential damages, arising out of the use of the content and data \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n© Hong Kong Productivity Council. All rights reserved. \\nPublished by Hong Kong Productivity Council \\nHKPC Building, 78 Tat Chee Avenue, Kowloon, Hong Kong \\nTel \\nFax \\nWebsite \\nEmail \\n  (852) 2788 5678 \\n  (852) 2788 5900 \\n  www.hkpc.org \\n  hkpcenq@hkpc.org'),\n","  Document(id='eb044e78-d774-4bc5-82c2-1d514e5451ca', metadata={'producer': '適用於 Microsoft 365 的 Microsoft® Word', 'creator': '適用於 Microsoft 365 的 Microsoft® Word', 'creationdate': '2022-11-18T12:34:46+08:00', 'author': 'HKCERT', 'moddate': '2022-11-18T12:45:00+08:00', 'title': 'HKT Hong Kong Enterprise Cyber Security Readiness Index 2022', 'source': './2022hkt_security_report.pdf', 'total_pages': 38, 'page': 1, 'page_label': '2'}, page_content='3.2 The Index ........................................................................................................................ 14 \\n3.3 Thematic Survey of the Year: Managed Security Services (MSS) ................................... 22 \\n3.4 Investment Plans in the Next 12 Months ....................................................................... 26 \\n4. Conclusion & Recommendations ............................................................... 30 \\n4.1 Key Findings .................................................................................................................... 30 \\n4.2 Recommendations .......................................................................................................... 33'),\n","  Document(id='4ed347ec-8f5a-4ad7-b2df-859c215a3a0e', metadata={'producer': '適用於 Microsoft 365 的 Microsoft® Word', 'creator': '適用於 Microsoft 365 的 Microsoft® Word', 'creationdate': '2022-11-18T12:34:46+08:00', 'author': 'HKCERT', 'moddate': '2022-11-18T12:45:00+08:00', 'title': 'HKT Hong Kong Enterprise Cyber Security Readiness Index 2022', 'source': './2022hkt_security_report.pdf', 'total_pages': 38, 'page': 4, 'page_label': '5'}, page_content='3 | P a g e \\n2. Methodology \\n2.1 Framework of the Index \\nThe Index is constructed by assessing the c omprehensiveness of security measures of the \\nsurveyed enterprises  in four key areas: Policy and Risk A ssessment, Technology Control, \\nProcess Control and Human Awareness. Questions in the four key areas are devised by \\ninformation security professional s according to cyber security development. The options \\ngiven to surveyed enterprises are classified in scores based on the comprehensiveness level. \\n \\nComponents of the Index  \\n \\nThe Index is composed of sub-indices from four aspects: \\n- Policy & Risk Assessment \\n- Technology Control \\n- Process Control  \\n- Human Awareness Building \\n \\n \\nOverall Index = Average of the Sub-Indices (rounded off to one decimal place) \\n \\nThe Index is calculated by assessing the  comprehensiveness of current security measures \\nadopted in four aspects: Policy and Risk Assessment, Technology Control, Process Control and')],\n"," 'answer': 'The document appears to be a report on a Cyber Security Readiness Index survey conducted by HKT and involves Hong Kong enterprises. It includes an introduction, methodology detailing the framework of the index, thematic surveys, investment plans, and concludes with key findings and recommendations. The index assesses security measures across four areas: Policy and Risk Assessment, Technology Control, Process Control, and Human Awareness Building.'}"]},"metadata":{},"execution_count":13}],"source":["from langchain.chains import create_retrieval_chain\n","from langchain.chains.combine_documents import create_stuff_documents_chain\n","from langchain_core.prompts import ChatPromptTemplate\n","\n","system_prompt = (\n","    \"You are an assistant for question-answering tasks. \"\n","    \"Use the following pieces of retrieved context to answer \"\n","    \"the question. If you don't know the answer, say that you \"\n","    \"don't know. Use three sentences maximum and keep the \"\n","    \"answer concise.\"\n","    \"\\n\\n\"\n","    \"{context}\"\n",")\n","\n","prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", system_prompt),\n","        (\"human\", \"{input}\"),\n","    ]\n",")\n","\n","\n","question_answer_chain = create_stuff_documents_chain(llm, prompt)\n","rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n","\n","results = rag_chain.invoke({\"input\": \"What's the content of the document?\"})\n","\n","results"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1739323509448,"user":{"displayName":"Wai Leuk Lo","userId":"04142260838791272738"},"user_tz":-480},"id":"N_iRPkoT0Dnf","outputId":"cfae31c2-8754-438f-8e7a-35266364c4af"},"outputs":[{"output_type":"stream","name":"stdout","text":["0 | P a g e \n","Table of Content \n"," \n","1. Introduction ................................................................................................ 1 \n","1.1 Background ....................................................................................................................... 1 \n","1.2 HKT Hong Kong Enterprise Cyber Security Readiness Index Survey ................................ 1 \n","1.3 Thematic Survey of the Year ............................................................................................ 2 \n","1.4 Structure of Report ........................................................................................................... 2 \n","2. Methodology .............................................................................................. 3 \n","2.1 Framework of the Index ................................................................................................... 3\n"]}],"source":["print(results[\"context\"][0].page_content)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1739323509454,"user":{"displayName":"Wai Leuk Lo","userId":"04142260838791272738"},"user_tz":-480},"id":"xmjokqAY1sBE","outputId":"9038df1c-d98c-4b8e-e304-1f935ee15748"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'producer': '適用於 Microsoft 365 的 Microsoft® Word', 'creator': '適用於 Microsoft 365 的 Microsoft® Word', 'creationdate': '2022-11-18T12:34:46+08:00', 'author': 'HKCERT', 'moddate': '2022-11-18T12:45:00+08:00', 'title': 'HKT Hong Kong Enterprise Cyber Security Readiness Index 2022', 'source': './2022hkt_security_report.pdf', 'total_pages': 38, 'page': 1, 'page_label': '2'}\n"]}],"source":["print(results[\"context\"][0].metadata)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":1299,"status":"ok","timestamp":1739323510754,"user":{"displayName":"Wai Leuk Lo","userId":"04142260838791272738"},"user_tz":-480},"id":"nQWZXo1J2Eyx"},"outputs":[],"source":["from tqdm.auto import tqdm\n","import pandas as pd\n","from typing import Optional, List, Tuple\n","import json\n","import datasets\n","\n","pd.set_option(\"display.max_colwidth\", None)"]},{"cell_type":"markdown","metadata":{"id":"7c5k3KAp4G3m"},"source":["## Set up agents for question generation"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":177},"executionInfo":{"elapsed":6337,"status":"ok","timestamp":1739323517093,"user":{"displayName":"Wai Leuk Lo","userId":"04142260838791272738"},"user_tz":-480},"id":"49xip_fT4Ek-","outputId":"8a9fed56-80a1-43e7-c875-4f05267b2f4a"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["' for the `@mui/material` library.\\n\\n## Installation\\n\\n```sh\\nnpm install @mui/material\\n```\\n\\n## Usage\\n\\n```jsx\\nimport React from \\'react\\';\\nimport { Button } from \\'@mui/material\\';\\n\\nfunction App() {\\n  return (\\n    <div className=\"App\">\\n      <Button variant=\"contained\" color=\"primary\">\\n        Hello World\\n      </Button>\\n    </div>\\n  );\\n}\\n\\nexport default App;\\n```\\n\\n## Documentation\\n\\n- [Material-UI](https://material-ui.com/)\\n- [Material Design](https://material.io/)'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":17}],"source":["from huggingface_hub import InferenceClient\n","\n","\n","repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n","\n","llm_client = InferenceClient(\n","    model=repo_id,\n","    timeout=120,\n",")\n","\n","\n","def call_llm(inference_client: InferenceClient, prompt: str):\n","    response = inference_client.text_generation(\n","        prompt=prompt,\n","        max_new_tokens=1000\n","    )\n","    return response\n","\n","\n","call_llm(llm_client, \"This is a test context\")"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1739323517105,"user":{"displayName":"Wai Leuk Lo","userId":"04142260838791272738"},"user_tz":-480},"id":"Q-054J0E4QcR"},"outputs":[],"source":["QA_generation_prompt = \"\"\"\n","Your task is to write a factoid question and an answer given a context.\n","Your factoid question should be answerable with a specific, concise piece of factual information from the context.\n","Your factoid question should be formulated in the same style as questions users could ask in a search engine.\n","This means that your factoid question MUST NOT mention something like \"according to the passage\" or \"context\".\n","\n","Provide your answer as follows:\n","\n","Output:::\n","Factoid question: (your factoid question)\n","Answer: (your answer to the factoid question)\n","\n","Now here is the context.\n","\n","Context: {context}\\n\n","Output:::\"\"\""]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":267112,"status":"ok","timestamp":1739323784219,"user":{"displayName":"Wai Leuk Lo","userId":"04142260838791272738"},"user_tz":-480},"id":"BPvnH80i4WUX","outputId":"a9c98008-0cc7-43c1-e203-54bde687252e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generating 145 QA couples...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 145/145 [04:27<00:00,  1.84s/it]\n"]}],"source":["from tqdm import tqdm\n","\n","print(f\"Generating {len(splits)} QA couples...\")\n","\n","outputs = []\n","for context in tqdm(splits):\n","    # Generate QA couple\n","    output_QA_couple = call_llm(llm_client, QA_generation_prompt.format(context=context.page_content))\n","    try:\n","        question = output_QA_couple.split(\"Factoid question: \")[-1].split(\"Answer: \")[0]\n","        answer = output_QA_couple.split(\"Answer: \")[-1]\n","        assert len(answer) < 300, \"Answer is too long\"\n","        outputs.append(\n","            {\n","                \"context\": context.page_content,\n","                \"question\": question,\n","                \"answer\": answer,\n","                \"source_doc\": context.metadata[\"source\"],\n","            }\n","        )\n","    except:\n","        continue"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":588},"executionInfo":{"elapsed":147,"status":"ok","timestamp":1739323784370,"user":{"displayName":"Wai Leuk Lo","userId":"04142260838791272738"},"user_tz":-480},"id":"LhbwFTs7aoL0","outputId":"bcfa1c6f-6866-4040-897e-3404cfd8d030"},"outputs":[{"output_type":"display_data","data":{"text/plain":["                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                context  \\\n","0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      HKT Hong Kong Enterprise \\nCyber Security Readiness \\nIndex 2022 \\n \\nApril 2018   \n","1                                                                                               0 | P a g e \\nTable of Content \\n \\n1. Introduction ................................................................................................ 1 \\n1.1 Background ....................................................................................................................... 1 \\n1.2 HKT Hong Kong Enterprise Cyber Security Readiness Index Survey ................................ 1 \\n1.3 Thematic Survey of the Year ............................................................................................ 2 \\n1.4 Structure of Report ........................................................................................................... 2 \\n2. Methodology .............................................................................................. 3 \\n2.1 Framework of the Index ................................................................................................... 3   \n","2        1.2 HKT Hong Kong Enterprise Cyber Security Readiness Index Survey ................................ 1 \\n1.3 Thematic Survey of the Year ............................................................................................ 2 \\n1.4 Structure of Report ........................................................................................................... 2 \\n2. Methodology .............................................................................................. 3 \\n2.1 Framework of the Index ................................................................................................... 3 \\n2.2 Sample Distribution .......................................................................................................... 4 \\n2.3 Profile of Surveyed Enterprises ........................................................................................ 5 \\n3. Survey Findings ........................................................................................... 7   \n","3  2. Methodology .............................................................................................. 3 \\n2.1 Framework of the Index ................................................................................................... 3 \\n2.2 Sample Distribution .......................................................................................................... 4 \\n2.3 Profile of Surveyed Enterprises ........................................................................................ 5 \\n3. Survey Findings ........................................................................................... 7 \\n3.1 Cyber Security Environment ............................................................................................. 7 \\n3.2 The Index ........................................................................................................................ 14 \\n3.3 Thematic Survey of the Year: Managed Security Services (MSS) ................................... 22   \n","4                      2.3 Profile of Surveyed Enterprises ........................................................................................ 5 \\n3. Survey Findings ........................................................................................... 7 \\n3.1 Cyber Security Environment ............................................................................................. 7 \\n3.2 The Index ........................................................................................................................ 14 \\n3.3 Thematic Survey of the Year: Managed Security Services (MSS) ................................... 22 \\n3.4 Investment Plans in the Next 12 Months ....................................................................... 26 \\n4. Conclusion & Recommendations ............................................................... 30 \\n4.1 Key Findings .................................................................................................................... 30   \n","\n","                                                               question  \\\n","0                       What is the name of the index in the context?\\n   \n","1            What is the name of the survey mentioned in the context?\\n   \n","2                                    What is the title of the report?\\n   \n","3  What is the title of the thematic survey of the year in the index?\\n   \n","4               What is the title of the third section of the report?\\n   \n","\n","                                                                                                                   answer  \\\n","0               The name of the index in the context is the HKT Hong Kong Enterprise Cyber Security Readiness Index 2022.   \n","1  The name of the survey mentioned in the context is the HKT Hong Kong Enterprise Cyber Security Readiness Index Survey.   \n","2                        The title of the report is '1.2 HKT Hong Kong Enterprise Cyber Security Readiness Index Survey'.   \n","3                                                                                         Managed Security Services (MSS)   \n","4                                                                                                               The Index   \n","\n","                      source_doc  \n","0  ./2022hkt_security_report.pdf  \n","1  ./2022hkt_security_report.pdf  \n","2  ./2022hkt_security_report.pdf  \n","3  ./2022hkt_security_report.pdf  \n","4  ./2022hkt_security_report.pdf  "],"text/html":["\n","  <div id=\"df-920aeef1-ffd0-4393-b8ec-48d2f1e20524\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>context</th>\n","      <th>question</th>\n","      <th>answer</th>\n","      <th>source_doc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>HKT Hong Kong Enterprise \\nCyber Security Readiness \\nIndex 2022 \\n \\nApril 2018</td>\n","      <td>What is the name of the index in the context?\\n</td>\n","      <td>The name of the index in the context is the HKT Hong Kong Enterprise Cyber Security Readiness Index 2022.</td>\n","      <td>./2022hkt_security_report.pdf</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0 | P a g e \\nTable of Content \\n \\n1. Introduction ................................................................................................ 1 \\n1.1 Background ....................................................................................................................... 1 \\n1.2 HKT Hong Kong Enterprise Cyber Security Readiness Index Survey ................................ 1 \\n1.3 Thematic Survey of the Year ............................................................................................ 2 \\n1.4 Structure of Report ........................................................................................................... 2 \\n2. Methodology .............................................................................................. 3 \\n2.1 Framework of the Index ................................................................................................... 3</td>\n","      <td>What is the name of the survey mentioned in the context?\\n</td>\n","      <td>The name of the survey mentioned in the context is the HKT Hong Kong Enterprise Cyber Security Readiness Index Survey.</td>\n","      <td>./2022hkt_security_report.pdf</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.2 HKT Hong Kong Enterprise Cyber Security Readiness Index Survey ................................ 1 \\n1.3 Thematic Survey of the Year ............................................................................................ 2 \\n1.4 Structure of Report ........................................................................................................... 2 \\n2. Methodology .............................................................................................. 3 \\n2.1 Framework of the Index ................................................................................................... 3 \\n2.2 Sample Distribution .......................................................................................................... 4 \\n2.3 Profile of Surveyed Enterprises ........................................................................................ 5 \\n3. Survey Findings ........................................................................................... 7</td>\n","      <td>What is the title of the report?\\n</td>\n","      <td>The title of the report is '1.2 HKT Hong Kong Enterprise Cyber Security Readiness Index Survey'.</td>\n","      <td>./2022hkt_security_report.pdf</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2. Methodology .............................................................................................. 3 \\n2.1 Framework of the Index ................................................................................................... 3 \\n2.2 Sample Distribution .......................................................................................................... 4 \\n2.3 Profile of Surveyed Enterprises ........................................................................................ 5 \\n3. Survey Findings ........................................................................................... 7 \\n3.1 Cyber Security Environment ............................................................................................. 7 \\n3.2 The Index ........................................................................................................................ 14 \\n3.3 Thematic Survey of the Year: Managed Security Services (MSS) ................................... 22</td>\n","      <td>What is the title of the thematic survey of the year in the index?\\n</td>\n","      <td>Managed Security Services (MSS)</td>\n","      <td>./2022hkt_security_report.pdf</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2.3 Profile of Surveyed Enterprises ........................................................................................ 5 \\n3. Survey Findings ........................................................................................... 7 \\n3.1 Cyber Security Environment ............................................................................................. 7 \\n3.2 The Index ........................................................................................................................ 14 \\n3.3 Thematic Survey of the Year: Managed Security Services (MSS) ................................... 22 \\n3.4 Investment Plans in the Next 12 Months ....................................................................... 26 \\n4. Conclusion &amp; Recommendations ............................................................... 30 \\n4.1 Key Findings .................................................................................................................... 30</td>\n","      <td>What is the title of the third section of the report?\\n</td>\n","      <td>The Index</td>\n","      <td>./2022hkt_security_report.pdf</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-920aeef1-ffd0-4393-b8ec-48d2f1e20524')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-920aeef1-ffd0-4393-b8ec-48d2f1e20524 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-920aeef1-ffd0-4393-b8ec-48d2f1e20524');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-4252fc51-394b-4464-9732-11187e714848\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4252fc51-394b-4464-9732-11187e714848')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-4252fc51-394b-4464-9732-11187e714848 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"display(pd\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"0 | P a g e \\nTable of Content \\n \\n1. Introduction ................................................................................................ 1 \\n1.1 Background ....................................................................................................................... 1 \\n1.2 HKT Hong Kong Enterprise Cyber Security Readiness Index Survey ................................ 1 \\n1.3 Thematic Survey of the Year ............................................................................................ 2 \\n1.4 Structure of Report ........................................................................................................... 2 \\n2. Methodology .............................................................................................. 3 \\n2.1 Framework of the Index ................................................................................................... 3\",\n          \"2.3 Profile of Surveyed Enterprises ........................................................................................ 5 \\n3. Survey Findings ........................................................................................... 7 \\n3.1 Cyber Security Environment ............................................................................................. 7 \\n3.2 The Index ........................................................................................................................ 14 \\n3.3 Thematic Survey of the Year: Managed Security Services (MSS) ................................... 22 \\n3.4 Investment Plans in the Next 12 Months ....................................................................... 26 \\n4. Conclusion & Recommendations ............................................................... 30 \\n4.1 Key Findings .................................................................................................................... 30\",\n          \"1.2 HKT Hong Kong Enterprise Cyber Security Readiness Index Survey ................................ 1 \\n1.3 Thematic Survey of the Year ............................................................................................ 2 \\n1.4 Structure of Report ........................................................................................................... 2 \\n2. Methodology .............................................................................................. 3 \\n2.1 Framework of the Index ................................................................................................... 3 \\n2.2 Sample Distribution .......................................................................................................... 4 \\n2.3 Profile of Surveyed Enterprises ........................................................................................ 5 \\n3. Survey Findings ........................................................................................... 7\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"What is the name of the survey mentioned in the context?\\n\",\n          \"What is the title of the third section of the report?\\n\",\n          \"What is the title of the report?\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The name of the survey mentioned in the context is the HKT Hong Kong Enterprise Cyber Security Readiness Index Survey.\",\n          \"The Index\",\n          \"The title of the report is '1.2 HKT Hong Kong Enterprise Cyber Security Readiness Index Survey'.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_doc\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"./2022hkt_security_report.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}],"source":["display(pd.DataFrame(outputs).head(5))"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1739323784374,"user":{"displayName":"Wai Leuk Lo","userId":"04142260838791272738"},"user_tz":-480},"id":"dSoC_ZRydlMa"},"outputs":[],"source":["question_groundedness_critique_prompt = \"\"\"\n","You will be given a context and a question.\n","Your task is to provide a 'total rating' scoring how well one can answer the given question unambiguously with the given context.\n","Give your answer on a scale of 1 to 5, where 1 means that the question is not answerable at all given the context, and 5 means that the question is clearly and unambiguously answerable with the context.\n","\n","Provide your answer as follows:\n","\n","Answer:::\n","Evaluation: (your rationale for the rating, as a text)\n","Total rating: (your rating, as a number between 1 and 5)\n","\n","You MUST provide values for 'Evaluation:' and 'Total rating:' in your answer.\n","\n","Now here are the question and context.\n","\n","Question: {question}\\n\n","Context: {context}\\n\n","Answer::: \"\"\"\n","\n","question_relevance_critique_prompt = \"\"\"\n","You will be given a question.\n","Your task is to provide a 'total rating' representing how useful this question can be to customers from the information technology sector.\n","Give your answer on a scale of 1 to 5, where 1 means that the question is not useful at all, and 5 means that the question is extremely useful.\n","\n","Provide your answer as follows:\n","\n","Answer:::\n","Evaluation: (your rationale for the rating, as a text)\n","Total rating: (your rating, as a number between 1 and 5)\n","\n","You MUST provide values for 'Evaluation:' and 'Total rating:' in your answer.\n","\n","Now here is the question.\n","\n","Question: {question}\\n\n","Answer::: \"\"\"\n","\n","question_standalone_critique_prompt = \"\"\"\n","You will be given a question.\n","Your task is to provide a 'total rating' representing how context-independant this question is.\n","Give your answer on a scale of 1 to 5, where 1 means that the question depends on additional information to be understood, and 5 means that the question makes sense by itself.\n","For instance, if the question refers to a particular setting, like 'in the context' or 'in the document', the rating must be 1.\n","The questions can contain obscure technical nouns or acronyms like Gradio, Hub, Hugging Face or Space and still be a 5: it must simply be clear to an operator with access to documentation what the question is about.\n","\n","For instance, \"What is the methodology of this report?\" should receive a 1, since there is an implicit mention of a context, thus the question is not independant from the context.\n","\n","Provide your answer as follows:\n","\n","Answer:::\n","Evaluation: (your rationale for the rating, as a text)\n","Total rating: (your rating, as a number between 1 and 5)\n","\n","You MUST provide values for 'Evaluation:' and 'Total rating:' in your answer.\n","\n","Now here is the question.\n","\n","Question: {question}\\n\n","Answer::: \"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m6WNXlsueCfG","outputId":"80fc3cf9-98c0-47db-b7fe-72e050ff305b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generating critique for each QA couple...\n"]},{"output_type":"stream","name":"stderr","text":[" 84%|████████▍ | 119/142 [1:06:55<13:10, 34.36s/it]"]}],"source":["print(\"Generating critique for each QA couple...\")\n","for output in tqdm(outputs):\n","    evaluations = {\n","        \"groundedness\": call_llm(\n","            llm_client,\n","            question_groundedness_critique_prompt.format(context=output[\"context\"], question=output[\"question\"]),\n","        ),\n","        \"relevance\": call_llm(\n","            llm_client,\n","            question_relevance_critique_prompt.format(question=output[\"question\"]),\n","        ),\n","        \"standalone\": call_llm(\n","            llm_client,\n","            question_standalone_critique_prompt.format(question=output[\"question\"]),\n","        ),\n","    }\n","    try:\n","        for criterion, evaluation in evaluations.items():\n","            score, eval = (\n","                int(evaluation.split(\"Total rating: \")[-1].strip()),\n","                evaluation.split(\"Total rating: \")[-2].split(\"Evaluation: \")[1],\n","            )\n","            output.update(\n","                {\n","                    f\"{criterion}_score\": score,\n","                    f\"{criterion}_eval\": eval,\n","                }\n","            )\n","    except Exception as e:\n","        continue"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YBduIFVClkTQ"},"outputs":[],"source":["import pandas as pd\n","\n","pd.set_option(\"display.max_colwidth\", None)\n","\n","generated_questions = pd.DataFrame.from_dict(outputs)\n","\n","print(\"Evaluation dataset before filtering:\")\n","display(\n","    generated_questions[\n","        [\n","            \"question\",\n","            \"answer\",\n","            \"groundedness_score\",\n","            \"relevance_score\",\n","            \"standalone_score\",\n","        ]\n","    ]\n",")\n","generated_questions = generated_questions.loc[\n","    (generated_questions[\"groundedness_score\"] >= 4)\n","    & (generated_questions[\"relevance_score\"] >= 4)\n","    & (generated_questions[\"standalone_score\"] >= 4)\n","]\n","print(\"============================================\")\n","print(\"Final evaluation dataset:\")\n","display(\n","    generated_questions[\n","        [\n","            \"question\",\n","            \"answer\",\n","            \"groundedness_score\",\n","            \"relevance_score\",\n","            \"standalone_score\",\n","        ]\n","    ]\n",")\n","\n","eval_dataset = datasets.Dataset.from_pandas(generated_questions, split=\"train\", preserve_index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jAEWz0NVZV9T"},"outputs":[],"source":["# Save the final generated questions to save the generation process in the future\n","import os\n","if not os.path.exists(\"./data/datasets/\"):\n","    os.mkdir(\"./data/datasets/\")\n","\n","with open('./data/datasets/generated_questions.json', 'w') as f:\n","    json.dump(generated_questions.to_dict(), f, indent=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FIi1XB6BcP3a"},"outputs":[],"source":["with open('./data/datasets/generated_questions.json', 'r') as f:\n","    generated_questions = json.load(f)\n","generated_questions = pd.DataFrame(generated_questions)\n","eval_dataset = datasets.Dataset.from_pandas(generated_questions, split=\"train\", preserve_index=False)"]},{"cell_type":"markdown","metadata":{"id":"2HTO4gKGD5cQ"},"source":["# Build RAG System"]},{"cell_type":"markdown","metadata":{"id":"2dQQ9E-LEELl"},"source":["## Indexing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vpmtG-rSDOGx"},"outputs":[],"source":["# Load\n","# The loading step is already done when we use a text splitter to split\n","# our pdf document into small chunks/documents with 1000 characters each\n","\n","# Split\n","# Here we will further split each small document into snippets for retrieval\n","from langchain.docstore.document import Document as LangchainDocument\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from transformers import AutoTokenizer\n","\n","\n","def split_documents(\n","    chunk_size: int,\n","    knowledge_base: List[LangchainDocument],\n","    tokenizer_name: str,\n",") -> List[LangchainDocument]:\n","    \"\"\"\n","    Split documents into chunks of size `chunk_size` characters and return a list of documents.\n","    \"\"\"\n","    text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n","        AutoTokenizer.from_pretrained(tokenizer_name),\n","        chunk_size=chunk_size,\n","        chunk_overlap=int(chunk_size / 10),\n","        add_start_index=True,\n","        strip_whitespace=True,\n","        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n","    )\n","\n","    docs_processed = []\n","    for doc in knowledge_base:\n","        docs_processed += text_splitter.split_documents([doc])\n","\n","    # Remove duplicates\n","    unique_texts = {}\n","    docs_processed_unique = []\n","    for doc in docs_processed:\n","        if doc.page_content not in unique_texts:\n","            unique_texts[doc.page_content] = True\n","            docs_processed_unique.append(doc)\n","\n","    return docs_processed_unique\n","\n","# Store\n","# Embed the snippets in vectors and store them in a vectorestore\n","from langchain.vectorstores import FAISS\n","from langchain_community.embeddings import HuggingFaceEmbeddings\n","from langchain_community.vectorstores.utils import DistanceStrategy\n","import os\n","\n","def load_embeddings(\n","    langchain_docs: List[LangchainDocument],\n","    chunk_size: int,\n","    embedding_model_name: Optional[str] = \"thenlper/gte-small\",\n",") -> FAISS:\n","    \"\"\"\n","    Creates a FAISS index from the given embedding model and documents. Loads the index directly if it already exists.\n","\n","    Args:\n","        langchain_docs: list of documents\n","        chunk_size: size of the chunks to split the documents into\n","        embedding_model_name: name of the embedding model to use\n","\n","    Returns:\n","        FAISS index\n","    \"\"\"\n","    # load embedding_model\n","    embedding_model = HuggingFaceEmbeddings(\n","        model_name=embedding_model_name,\n","        multi_process=True,\n","        model_kwargs={\"device\": \"cuda\"},\n","        encode_kwargs={\"normalize_embeddings\": True},  # set True to compute cosine similarity\n","    )\n","\n","    # Check if embeddings already exist on disk\n","    index_name = f\"index_chunk:{chunk_size}_embeddings:{embedding_model_name.replace('/', '~')}\"\n","    index_folder_path = f\"./data/indexes/{index_name}/\"\n","    if os.path.isdir(index_folder_path):\n","        return FAISS.load_local(\n","            index_folder_path,\n","            embedding_model,\n","            distance_strategy=DistanceStrategy.COSINE,\n","            allow_dangerous_deserialization=True\n","        )\n","\n","    else:\n","        print(\"Index not found, generating it...\")\n","        docs_processed = split_documents(\n","            chunk_size,\n","            langchain_docs,\n","            embedding_model_name,\n","        )\n","        knowledge_index = FAISS.from_documents(\n","            docs_processed, embedding_model, distance_strategy=DistanceStrategy.COSINE\n","        )\n","        knowledge_index.save_local(index_folder_path)\n","        return knowledge_index"]},{"cell_type":"markdown","metadata":{"id":"iiz33rMUK1Z4"},"source":["## Retrieval and Generation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JJD2Q8ZzF5Un"},"outputs":[],"source":["RAG_PROMPT_TEMPLATE = \"\"\"\n","<|system|>\n","Using the information contained in the context,\n","give a comprehensive answer to the question.\n","Respond only to the question asked, response should be concise and relevant to the question.\n","Provide the number of the source document when relevant.\n","If the answer cannot be deduced from the context, do not give an answer.</s>\n","<|user|>\n","Context:\n","{context}\n","---\n","Now here is the question you need to answer.\n","\n","Question: {question}\n","</s>\n","<|assistant|>\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aKRElS5PLIqO"},"outputs":[],"source":["from langchain_community.llms import HuggingFaceHub\n","\n","repo_id = \"HuggingFaceH4/zephyr-7b-beta\"\n","READER_MODEL_NAME = \"zephyr-7b-beta\"\n","\n","READER_LLM = HuggingFaceHub(\n","    repo_id=repo_id,\n","    task=\"text-generation\",\n","    model_kwargs={\n","        \"max_new_tokens\": 512,\n","        \"top_k\": 30,\n","        \"temperature\": 0.1,\n","        \"repetition_penalty\": 1.03,\n","    },\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vApHNKD1MI3m"},"outputs":[],"source":["from ragatouille import RAGPretrainedModel\n","from langchain_core.vectorstores import VectorStore\n","from langchain_core.language_models.llms import LLM\n","\n","def answer_with_rag(\n","    question: str,\n","    llm: LLM,\n","    knowledge_index: VectorStore,\n","    reranker: Optional[RAGPretrainedModel] = None,\n","    num_retrieved_docs: int = 5,\n","    num_docs_final: int = 3,\n",") -> Tuple[str, List[LangchainDocument]]:\n","    \"\"\"Answer a question using RAG with the given knowledge index.\"\"\"\n","    # Gather documents with retriever\n","    relevant_docs = knowledge_index.similarity_search(query=question, k=num_retrieved_docs)\n","    relevant_docs = [doc.page_content for doc in relevant_docs]  # keep only the text\n","\n","    # Optionally rerank results\n","    if reranker:\n","        relevant_docs = reranker.rerank(question, relevant_docs, k=num_docs_final)\n","        relevant_docs = [doc[\"content\"] for doc in relevant_docs]\n","\n","    relevant_docs = relevant_docs[:num_docs_final]\n","\n","    # Build the final prompt\n","    context = \"\\nExtracted documents:\\n\"\n","    context += \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(relevant_docs)])\n","\n","    final_prompt = RAG_PROMPT_TEMPLATE.format(question=question, context=context)\n","\n","    # Redact an answer\n","    answer = llm(final_prompt)\n","\n","    return answer, relevant_docs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"09CKTouZNPj2"},"outputs":[],"source":["for item in tqdm(eval_dataset):\n","    print(item['context'])\n","    break"]},{"cell_type":"markdown","metadata":{"id":"Q9L7gq0eMeSp"},"source":["# Evaluate RAG System"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LaAs0Uz8MKMy"},"outputs":[],"source":["from langchain_core.language_models import BaseChatModel\n","\n","\n","def run_rag_tests(\n","    eval_dataset: datasets.Dataset,\n","    llm,\n","    knowledge_index: VectorStore,\n","    output_file: str,\n","    reranker: Optional[RAGPretrainedModel] = None,\n","    verbose: Optional[bool] = True,\n","    test_settings: Optional[str] = None,  # To document the test settings used\n","):\n","    \"\"\"Runs RAG tests on the given dataset and saves the results to the given output file.\"\"\"\n","    try:  # load previous generations if they exist\n","        with open(output_file, \"r\") as f:\n","            outputs = json.load(f)\n","    except:\n","        outputs = []\n","\n","    for example in tqdm(eval_dataset):\n","        question = example[\"question\"]\n","        if question in [output[\"question\"] for output in outputs]:\n","            continue\n","\n","        answer, relevant_docs = answer_with_rag(question, llm, knowledge_index, reranker=reranker)\n","        if verbose:\n","            print(\"=======================================================\")\n","            print(f\"Question: {question}\")\n","            print(f\"Answer: {answer}\")\n","            print(f'True answer: {example[\"answer\"]}')\n","        result = {\n","            \"question\": question,\n","            \"context\": example[\"context\"],\n","            \"true_answer\": example[\"answer\"],\n","            \"source_doc\": example[\"source_doc\"],\n","            \"generated_answer\": answer,\n","            \"retrieved_docs\": [doc for doc in relevant_docs],\n","        }\n","        if test_settings:\n","            result[\"test_settings\"] = test_settings\n","        outputs.append(result)\n","\n","        with open(output_file, \"w\") as f:\n","            json.dump(outputs, f, indent=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZXEvw7rTN_Aa"},"outputs":[],"source":["EVALUATION_PROMPT = \"\"\"###Task Description:\n","An instruction (might include an Input inside it), a response to evaluate, a reference answer that gets a score of 5, and a score rubric representing a evaluation criteria are given.\n","1. Write a detailed feedback that assess the quality of the response strictly based on the given score rubric, not evaluating in general.\n","2. After writing a feedback, write a score that is an integer between 1 and 5. You should refer to the score rubric.\n","3. The output format should look as follows: \\\"Feedback: {{write a feedback for criteria}} [RESULT] {{an integer number between 1 and 5}}\\\"\n","4. Please do not generate any other opening, closing, and explanations. Be sure to include [RESULT] in your output.\n","\n","###The instruction to evaluate:\n","{instruction}\n","\n","###Response to evaluate:\n","{response}\n","\n","###Reference Answer (Score 5):\n","{reference_answer}\n","\n","###Score Rubrics:\n","[Is the response correct, accurate, and factual based on the reference answer?]\n","Score 1: The response is completely incorrect, inaccurate, and/or not factual.\n","Score 2: The response is mostly incorrect, inaccurate, and/or not factual.\n","Score 3: The response is somewhat correct, accurate, and/or factual.\n","Score 4: The response is mostly correct, accurate, and factual.\n","Score 5: The response is completely correct, accurate, and factual.\n","\n","###Feedback:\"\"\"\n","\n","from langchain.prompts.chat import (\n","    ChatPromptTemplate,\n","    HumanMessagePromptTemplate,\n",")\n","from langchain.schema import SystemMessage\n","\n","\n","evaluation_prompt_template = ChatPromptTemplate.from_messages(\n","    [\n","        SystemMessage(content=\"You are a fair evaluator language model.\"),\n","        HumanMessagePromptTemplate.from_template(EVALUATION_PROMPT),\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xP48dLxdOGcR"},"outputs":[],"source":["from langchain_openai import ChatOpenAI\n","\n","eval_chat_model = ChatOpenAI(model=\"gpt-4-1106-preview\", temperature=0)\n","evaluator_name = \"GPT4\"\n","\n","\n","def evaluate_answers(\n","    answer_path: str,\n","    eval_chat_model,\n","    evaluator_name: str,\n","    evaluation_prompt_template: ChatPromptTemplate,\n",") -> None:\n","    \"\"\"Evaluates generated answers. Modifies the given answer file in place for better checkpointing.\"\"\"\n","    answers = []\n","    if os.path.isfile(answer_path):  # load previous generations if they exist\n","        answers = json.load(open(answer_path, \"r\"))\n","\n","    for experiment in tqdm(answers):\n","        if f\"eval_score_{evaluator_name}\" in experiment:\n","            continue\n","\n","        eval_prompt = evaluation_prompt_template.format_messages(\n","            instruction=experiment[\"question\"],\n","            response=experiment[\"generated_answer\"],\n","            reference_answer=experiment[\"true_answer\"],\n","        )\n","        eval_result = eval_chat_model.invoke(eval_prompt)\n","        feedback, score = [item.strip() for item in eval_result.content.split(\"[RESULT]\")]\n","        experiment[f\"eval_score_{evaluator_name}\"] = score\n","        experiment[f\"eval_feedback_{evaluator_name}\"] = feedback\n","\n","        with open(answer_path, \"w\") as f:\n","            json.dump(answers, f, indent=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BXXTS-3TOP01"},"outputs":[],"source":["if not os.path.exists(\"./output\"):\n","    os.mkdir(\"./output\")\n","\n","for chunk_size in [200, 400, 600]:  # Add other chunk sizes (in tokens) as needed\n","    for embeddings in [\"thenlper/gte-small\"]:  # Add other embeddings as needed\n","        for rerank in [True, False]:\n","            settings_name = f\"chunk:{chunk_size}_embeddings:{embeddings.replace('/', '~')}_rerank:{rerank}_reader-model:{READER_MODEL_NAME}\"\n","            output_file_name = f\"./output/rag_{settings_name}.json\"\n","\n","            print(f\"Running evaluation for {settings_name}:\")\n","\n","            print(\"Loading knowledge base embeddings...\")\n","            knowledge_index = load_embeddings(\n","                splits,\n","                chunk_size=chunk_size,\n","                embedding_model_name=embeddings\n","            )\n","\n","            print(\"Running RAG...\")\n","            reranker = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\") if rerank else None\n","            run_rag_tests(\n","                eval_dataset=eval_dataset,\n","                llm=READER_LLM,\n","                knowledge_index=knowledge_index,\n","                output_file=output_file_name,\n","                reranker=reranker,\n","                verbose=False,\n","                test_settings=settings_name,\n","            )\n","\n","            print(\"Running evaluation...\")\n","            evaluate_answers(\n","                output_file_name,\n","                eval_chat_model,\n","                evaluator_name,\n","                evaluation_prompt_template,\n","            )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3AisXfVhO7iJ"},"outputs":[],"source":["import glob\n","\n","outputs = []\n","for file in glob.glob(\"./output/*.json\"):\n","    output = pd.DataFrame(json.load(open(file, \"r\")))\n","    output[\"settings\"] = file\n","    outputs.append(output)\n","result = pd.concat(outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QmSgnZxWYdJ4"},"outputs":[],"source":["result[\"eval_score_GPT4\"] = result[\"eval_score_GPT4\"].apply(lambda x: int(x) if isinstance(x, str) else 1)\n","result[\"eval_score_GPT4\"] = (result[\"eval_score_GPT4\"] - 1) / 4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MlrJsksiYsOx"},"outputs":[],"source":["average_scores = result.groupby(\"settings\")[\"eval_score_GPT4\"].mean()\n","settings = []\n","for setting in average_scores.index:\n","    chunk_size = setting.split('rag_chunk:')[1].split('_embeddings')[0]\n","    rerank = setting.split('rerank:')[1].split('_reader')[0]\n","    if rerank == 'True':\n","        settings.append('+'.join([chunk_size, 'reranker']))\n","    else:\n","        settings.append(chunk_size)\n","average_scores = pd.Series(average_scores.values, index=settings, name='eval_score_GPT4')\n","average_scores = average_scores * 100\n","average_scores.sort_values(inplace=True)\n","average_scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GD20jrnVYtn5"},"outputs":[],"source":["import plotly.express as px\n","fig = px.bar(\n","    average_scores,\n","    color=average_scores,\n","    labels={\n","        \"value\": \"Accuracy\",\n","        \"settings\": \"Configuration\",\n","    },\n","    color_continuous_scale=\"bluered\",\n",")\n","fig.update_layout(\n","    width=1000,\n","    height=600,\n","    barmode=\"group\",\n","    yaxis_range=[0, 100],\n","    title=\"<b>Accuracy of different RAG configurations</b>\",\n","    xaxis_title=\"RAG settings\",\n","    font=dict(size=15),\n",")\n","fig.layout.yaxis.ticksuffix = \"%\"\n","fig.update_coloraxes(showscale=False)\n","fig.update_traces(texttemplate=\"%{y:.1f}\", textposition=\"outside\")\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":273},"executionInfo":{"elapsed":424,"status":"error","timestamp":1728991642609,"user":{"displayName":"Wai Leuk Lo","userId":"04142260838791272738"},"user_tz":-480},"id":"Veqe3jEQ4gx-","outputId":"b5df0f8d-0297-472f-da79-b738b127327d"},"outputs":[{"ename":"ArrowInvalid","evalue":"Column 1 named reference expected length 34 but got length 37","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-898cfb2128d8>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\"retrieved_contexts\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"The Eiffel Tower is located in Paris.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m }\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcontext_precision\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# await context_precision.single_turn_ascore(sample)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mfrom_dict\u001b[0;34m(cls, mapping, features, info, split)\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0marrow_typed_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrow_typed_mapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m         \u001b[0mpa_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInMemoryTable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pydict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/table.py\u001b[0m in \u001b[0;36mfrom_pydict\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \"\"\"\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pydict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/table.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._Tabular.from_pydict\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/table.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._from_pydict\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/table.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.Table.from_arrays\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/table.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.Table.validate\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n","\u001b[0;31mArrowInvalid\u001b[0m: Column 1 named reference expected length 34 but got length 37"]}],"source":["from ragas import SingleTurnSample\n","from ragas import evaluate\n","# from ragas.metrics import LLMContextPrecisionWithReference\n","from ragas.metrics import context_precision\n","from datasets import Dataset\n","\n","# context_precision = LLMContextPrecisionWithReference()\n","\n","# sample = SingleTurnSample(\n","#     user_input=\"Where is the Eiffel Tower located?\",\n","#     reference=\"The Eiffel Tower is located in Paris.\",\n","#     retrieved_contexts=[\"The Eiffel Tower is located in Paris.\"],\n","# )\n","data = {\n","\"user_input\":\"Where is the Eiffel Tower located?\",\n","\"reference\": \"The Eiffel Tower is located in Paris.\",\n","\"retrieved_contexts\":\"The Eiffel Tower is located in Paris.\",\n","}\n","dataset = Dataset.from_dict(data)\n","evaluate(dataset, [context_precision])\n","# await context_precision.single_turn_ascore(sample)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GRXCngVLz9ii"},"outputs":[],"source":["from ragas.metrics import LLMContextPrecisionWithoutReference\n","from ragas.llms import LangchainLLMWrapper\n","from ragas import evaluate\n","\n","evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))\n","metrics = [LLMContextRecall(), FactualCorrectness(), Faithfulness()]\n","results = evaluate(dataset=sample, metrics=metrics, llm=evaluator_llm,)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":327},"executionInfo":{"elapsed":1098,"status":"error","timestamp":1729003160110,"user":{"displayName":"Wai Leuk Lo","userId":"04142260838791272738"},"user_tz":-480},"id":"ol_JzTbca3Z9","outputId":"c7966c1d-0d6f-4f1f-b593-c14869c50329"},"outputs":[{"ename":"AttributeError","evalue":"'SingleTurnSample' object has no attribute 'get_sample_type'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-06a31173d2b0>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mevaluator_llm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLangchainLLMWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mChatOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4o\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mLLMContextRecall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFactualCorrectness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFaithfulness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluator_llm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ragas/_analytics.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mtrack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIsCompleteEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_completed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtrack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIsCompleteEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_completed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ragas/evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(dataset, metrics, llm, embeddings, callbacks, in_ci, run_config, token_usage_parser, raise_exceptions, column_map, show_progress)\u001b[0m\n\u001b[1;32m    250\u001b[0m     )\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0msample_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sample_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    854\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                         \u001b[0;31m# this is the current error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{type(self).__name__!r} object has no attribute {item!r}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'SingleTurnSample' object has no attribute 'get_sample_type'"]}],"source":["# from ragas import SingleTurnSample\n","# from ragas.metrics import LLMContextPrecisionWithoutReference\n","\n","# context_precision = LLMContextPrecisionWithoutReference(llm=llm)\n","\n","sample = SingleTurnSample(\n","    user_input=\"Where is the Eiffel Tower located?\",\n","    reference=\"The Eiffel Tower is located in Paris.\",\n","    retrieved_contexts=[\"The Eiffel Tower is located in Paris.\"],\n",")\n","# await context_precision.single_turn_ascore(sample)\n","\n","from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, SemanticSimilarity\n","from ragas.llms import LangchainLLMWrapper\n","from ragas import evaluate\n","evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))\n","metrics = [LLMContextRecall(), FactualCorrectness(), Faithfulness()]\n","results = evaluate(dataset=sample, metrics=metrics, llm=evaluator_llm,)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":0}